{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess the training dataset\n",
        "train_df = pd.read_csv(\"/content/articles.csv\", encoding='latin1')\n",
        "train_df = train_df[['Heading', 'Full_Article', 'Article_Type']]\n",
        "train_df.dropna(inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "0afv67K86-fp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_df['Full_Article'])\n",
        "y_train = train_df['Article_Type']\n",
        "\n"
      ],
      "metadata": {
        "id": "LMGcaHn_8C59"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier model (SVM as an example)\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to disk\n",
        "joblib.dump(clf, 'your_model.pkl')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG43HLp58DC9",
        "outputId": "a2904ede-3950-4148-f587-ed9b1663b320"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['your_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the unknown article URLs\n",
        "unknown_df = pd.read_csv(\"/content/unknown_articles.csv\", nrows=10)\n",
        "\n",
        "# Initialize an empty list to store article predictions\n",
        "article_predictions = []\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iyyE5iMq8DGd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through URLs and scrape article content\n",
        "for url in unknown_df['Article.URL']:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Adjust the code to extract the relevant content based on the website structure\n",
        "        # For example, if the article text is in <p> tags, you can extract it as follows:\n",
        "        article_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "\n",
        "        # Vectorize the article content using the same vectorizer\n",
        "        X_unknown = vectorizer.transform([article_text])\n",
        "\n",
        "        # Predict the Article_type\n",
        "        prediction = clf.predict(X_unknown)\n",
        "        article_predictions.append(prediction[0])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {e}\")\n",
        "        article_predictions.append(None)"
      ],
      "metadata": {
        "id": "VCJsc0Je8DMf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predictions to the DataFrame\n",
        "unknown_df['Predicted_Article_type'] = article_predictions\n",
        "\n",
        "# Print or further analyze the results\n",
        "print(unknown_df[['Article.URL', 'Predicted_Article_type']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2oTK14T8S9_",
        "outputId": "e3ef2fec-a8e1-438c-fd33-adc5bc532ccd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Article.URL Predicted_Article_type\n",
            "0  http://australianaviation.com.au/2018/10/a-com...               Military\n",
            "1  http://australianaviation.com.au/2018/10/victo...             Commercial\n",
            "2  http://australianaviation.com.au/2018/10/army-...               Military\n",
            "3  https://attain.news/community/special-sea-king...               Military\n",
            "4  https://m.ariva.de/amp/ad-hoc-airbus-board-of-...             Executives\n",
            "5  http://m.ariva.de/amp/u-s-army-pilots-fly-auto...             Commercial\n",
            "6  https://www.arabianaerospace.aero/kuwait-h225-...             Commercial\n",
            "7  https://www.atlasinfo.fr/Marrakech-Air-Show-20...             Commercial\n",
            "8  https://www.atlasinfo.fr/Des-shows-aeriens-en-...             Commercial\n",
            "9  https://www.airmedandrescue.com/story/113203/l...             Commercial\n"
          ]
        }
      ]
    }
  ]
}